import concurrent.futures
from difflib import SequenceMatcher
import math
from core.prompts import get_split_prompt
from core.spacy_utils.load_nlp_model import init_nlp
from core.utils import *
from rich.console import Console
from rich.table import Table
from core.utils.models import _3_1_SPLIT_BY_NLP, _3_2_SPLIT_BY_MEANING
console = Console()

def tokenize_sentence(sentence, nlp):
    doc = nlp(sentence)
    return [token.text for token in doc]

def find_split_positions(original, modified):
    split_positions = []
    parts = modified.split('[br]')
    start = 0
    whisper_language = load_key("whisper.language")
    language = load_key("whisper.detected_language") if whisper_language == 'auto' else whisper_language
    joiner = get_joiner(language)

    for i in range(len(parts) - 1):
        max_similarity = 0
        best_split = None

        for j in range(start, len(original)):
            original_left = original[start:j]
            modified_left = joiner.join(parts[i].split())

            left_similarity = SequenceMatcher(None, original_left, modified_left).ratio()

            if left_similarity > max_similarity:
                max_similarity = left_similarity
                best_split = j

        if max_similarity < 0.9:
            console.print(f"[yellow]Warning: low similarity found at the best split point: {max_similarity}[/yellow]")
        if best_split is not None:
            split_positions.append(best_split)
            start = best_split
        else:
            console.print(f"[yellow]Warning: Unable to find a suitable split point for the {i+1}th part.[/yellow]")

    return split_positions

def split_sentence(sentence, num_parts, word_limit=20, index=-1, retry_attempt=0):
    """Split a long sentence using GPT and return the result as a string."""
    split_prompt = get_split_prompt(sentence, num_parts, word_limit)
    def valid_split(response_data, original_sentence=sentence):
        # æ·»åŠ è¯¦ç»†çš„å“åº”æ•°æ®æ—¥å¿—
        console.print(f"[cyan]Debug: æ”¶åˆ°çš„å“åº”æ•°æ®: {response_data}[/cyan]")
        console.print(f"[cyan]Debug: å“åº”æ•°æ®ç±»å‹: {type(response_data)}[/cyan]")
        console.print(f"[cyan]Debug: å“åº”æ•°æ®é”®: {list(response_data.keys()) if isinstance(response_data, dict) else 'Not a dict'}[/cyan]")
        
        # æ£€æŸ¥å“åº”æ•°æ®æ˜¯å¦ä¸ºå­—å…¸ç±»å‹
        if not isinstance(response_data, dict):
            console.print(f"[red]Error: å“åº”æ•°æ®ä¸æ˜¯å­—å…¸æ ¼å¼: {type(response_data)}[/red]")
            return {"status": "error", "message": "Response data is not a dictionary"}
        
        # åŠ¨æ€æŸ¥æ‰¾å¯ç”¨çš„splitå­—æ®µ
        available_split_keys = [k for k in response_data.keys() if k.startswith('split') and k != 'split']
        console.print(f"[cyan]Debug: å¯ç”¨çš„splitå­—æ®µ: {available_split_keys}[/cyan]")
        
        # ç¡®å®šè¦ä½¿ç”¨çš„splitå­—æ®µ
        split_key = None
        choice = None
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨choiceå­—æ®µ
        if "choice" in response_data:
            choice = str(response_data["choice"]).strip()
            console.print(f"[cyan]Debug: æ£€æµ‹åˆ°choiceå­—æ®µ: '{choice}'[/cyan]")
            
            # æ¸…ç†choiceå€¼ï¼Œç§»é™¤å¯èƒ½çš„é¢å¤–æ–‡æœ¬
            if choice and choice[0].isdigit():
                choice = choice[0]  # åªå–ç¬¬ä¸€ä¸ªæ•°å­—
            
            potential_key = f'split{choice}'
            if potential_key in response_data:
                split_key = potential_key
                console.print(f"[green]ä½¿ç”¨choiceæŒ‡å®šçš„å­—æ®µ: {split_key}[/green]")
        
        # å¦‚æœchoiceæ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„splitå­—æ®µ
        if not split_key and available_split_keys:
            split_key = available_split_keys[0]
            console.print(f"[yellow]choiceå­—æ®µæ— æ•ˆï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„splitå­—æ®µ: {split_key}[/yellow]")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°splitå­—æ®µï¼Œè¿”å›é”™è¯¯
        if not split_key:
            console.print(f"[red]Error: æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„splitå­—æ®µ[/red]")
            console.print(f"[yellow]Available keys: {list(response_data.keys())}[/yellow]")
            return {"status": "error", "message": "No valid split field found in response"}
        
        split_content = response_data[split_key]
        console.print(f"[cyan]Debug: æ£€æŸ¥çš„åˆ†å‰²å†…å®¹: {repr(split_content)}[/cyan]")
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹é•¿åº¦: {len(split_content)}[/cyan]")
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹æ˜¯å¦åŒ…å«<split_this_sentence>: {'<split_this_sentence>' in split_content}[/cyan]")
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹æ˜¯å¦åŒ…å«<split_this_paragraph>: {'<split_this_paragraph>' in split_content}[/cyan]")
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹æ˜¯å¦åŒ…å«[br]: {'[br]' in split_content}[/cyan]")
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹æ˜¯å¦åŒ…å«<br>: {'<br>' in split_content}[/cyan]")
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹æ˜¯å¦åŒ…å«</br>: {'</br>' in split_content}[/cyan]")
        has_newlines = ('\n' in split_content) or ('\r\n' in split_content)
        console.print(f"[cyan]Debug: åˆ†å‰²å†…å®¹æ˜¯å¦åŒ…å«æ¢è¡Œç¬¦: {has_newlines}[/cyan]")
        
        # å…¼å®¹å¤šç§å“åº”æ ¼å¼çš„éªŒè¯é€»è¾‘
        has_valid_split = False
        processed_content = split_content
        
        # æ£€æŸ¥æ ‡å‡†çš„[br]æ ‡è®°
        if "[br]" in split_content:
            has_valid_split = True
            console.print(f"[green]Found standard [br] markers[/green]")
        
        # æ£€æŸ¥qwen2æ ¼å¼ï¼šå„ç§splitæ ‡ç­¾åŒ…è£…çš„å†…å®¹
        elif ("<split_this_sentence>" in split_content and "</split_this_sentence>" in split_content) or \
             ("<split_this_paragraph>" in split_content and "</split_this_paragraph>" in split_content):
            # æå–æ ‡ç­¾å†…çš„å†…å®¹
            import re
            # å°è¯•åŒ¹é…ä¸åŒçš„æ ‡ç­¾æ ¼å¼
            match = re.search(r'<split_this_sentence>(.*?)</split_this_sentence>', split_content, re.DOTALL)
            if not match:
                match = re.search(r'<split_this_paragraph>(.*?)</split_this_paragraph>', split_content, re.DOTALL)
            
            if match:
                inner_content = match.group(1).strip()
                console.print(f"[cyan]Debug: æå–çš„å†…éƒ¨å†…å®¹: {repr(inner_content)}[/cyan]")
                
                # å…ˆæ£€æŸ¥å’Œè½¬æ¢bræ ‡è®°ï¼Œå†æ¸…ç†å…¶ä»–HTMLæ ‡ç­¾
                temp_content = inner_content
                
                # æ£€æŸ¥å†…éƒ¨å†…å®¹æ˜¯å¦åŒ…å«å„ç§bræ ‡è®°
                if "<br>" in temp_content or "</br>" in temp_content:
                    # å°†<br>å’Œ</br>éƒ½è½¬æ¢ä¸º[br]æ ‡è®°
                    temp_content = temp_content.replace('<br>', '[br]').replace('</br>', '[br]')
                    console.print(f"[green]Found <br> or </br> tags in qwen2 format[/green]")
                elif "\r\n" in temp_content or "\n" in temp_content:
                    # å°†æ¢è¡Œç¬¦è½¬æ¢ä¸º[br]æ ‡è®°
                    temp_content = temp_content.replace('\r\n', '[br]').replace('\n', '[br]')
                    console.print(f"[green]Found newlines in qwen2 format[/green]")
                
                # æ¸…ç†å…¶ä»–HTMLæ ‡ç­¾ï¼ˆä¿ç•™[br]æ ‡è®°ï¼‰
                import re
                # å…ˆä¿æŠ¤[br]æ ‡è®°
                temp_content = temp_content.replace('[br]', '___BR_PLACEHOLDER___')
                # æ¸…ç†HTMLæ ‡ç­¾
                cleaned_content = re.sub(r'<[^>]+>', '', temp_content)
                # æ¢å¤[br]æ ‡è®°
                processed_content = cleaned_content.replace('___BR_PLACEHOLDER___', '[br]')
                
                console.print(f"[cyan]Debug: å¤„ç†åçš„å†…å®¹: {repr(processed_content)}[/cyan]")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„åˆ†å‰²æ ‡è®°
                if '[br]' not in processed_content:
                    console.print(f"[yellow]No [br] markers found after processing, using cleaned content anyway[/yellow]")
                    # å³ä½¿æ²¡æœ‰[br]æ ‡è®°ï¼Œä¹Ÿä½¿ç”¨æ¸…ç†åçš„å†…å®¹
                    # è¿™æ ·è‡³å°‘å¯ä»¥å»é™¤HTMLæ ‡ç­¾
                
                # æ›´æ–°response_dataä¸­çš„å†…å®¹
                response_data[split_key] = processed_content
                has_valid_split = True
                console.print(f"[green]Successfully processed qwen2 format content[/green]")
        
        # æ£€æŸ¥æ˜¯å¦ç›´æ¥åŒ…å«<br>æ ‡è®°ï¼ˆHTMLæ ¼å¼ï¼‰
        elif "<br>" in split_content or "</br>" in split_content:
            # å°†<br>å’Œ</br>éƒ½è½¬æ¢ä¸º[br]æ ‡è®°
            processed_content = split_content.replace('<br>', '[br]').replace('</br>', '[br]')
            response_data[split_key] = processed_content
            has_valid_split = True
            console.print(f"[green]Found <br> or </br> tags, converted to: {processed_content}[/green]")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¢è¡Œç¬¦ï¼ˆå¯èƒ½çš„åˆ†å‰²æ ‡è®°ï¼‰
        elif '\n' in split_content or '\r\n' in split_content:
            # å°†æ¢è¡Œç¬¦è½¬æ¢ä¸º[br]æ ‡è®°
            processed_content = split_content.replace('\r\n', '[br]').replace('\n', '[br]')
            response_data[split_key] = processed_content
            has_valid_split = True
            console.print(f"[green]Found newline separators, converted to: {processed_content}[/green]")
        
        if not has_valid_split:
            console.print(f"[yellow]Warning: åˆ†å‰²å†…å®¹ä¸­æ²¡æœ‰æ‰¾åˆ°æ ‡å‡†åˆ†å‰²æ ‡è®°ï¼Œå°è¯•æ™ºèƒ½åˆ†å‰²[/yellow]")
            console.print(f"[cyan]å®é™…å†…å®¹: {repr(split_content)}[/cyan]")
            
            # æ™ºèƒ½åˆ†å‰²é€»è¾‘ï¼šå°è¯•æ ¹æ®æ ‡ç‚¹ç¬¦å·ã€è¿è¯ç­‰è¿›è¡Œåˆ†å‰²
            processed_content = split_content.strip()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„åˆ†å‰²ç‚¹
            split_patterns = [
                # ä¸­æ–‡æ ‡ç‚¹
                'ï¼Œ', 'ã€‚', 'ï¼›', 'ï¼š', 'ï¼', 'ï¼Ÿ', 'ã€',
                # è‹±æ–‡æ ‡ç‚¹
                ',', '.', ';', ':', '!', '?',
                # è¿è¯
                ' and ', ' but ', ' or ', ' so ', ' yet ', ' for ', ' nor ',
                ' å’Œ ', ' ä½†æ˜¯ ', ' æˆ–è€… ', ' æ‰€ä»¥ ', ' ç„¶è€Œ ', ' å› ä¸º ',
                # å…¶ä»–å¯èƒ½çš„åˆ†å‰²ç‚¹
                ' that ', ' which ', ' who ', ' when ', ' where ', ' why ', ' how ',
                ' çš„ ', ' åœ¨ ', ' æ˜¯ ', ' æœ‰ ', ' ä¼š ', ' èƒ½ ', ' è¦ '
            ]
            
            # å¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹ï¼ˆå°½é‡åœ¨ä¸­é—´ä½ç½®ï¼‰
            best_split_pos = len(processed_content) // 2
            min_distance = float('inf')
            
            for pattern in split_patterns:
                if pattern in processed_content:
                    # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…ä½ç½®
                    pos = processed_content.find(pattern)
                    while pos != -1:
                        # è®¡ç®—ä¸ä¸­é—´ä½ç½®çš„è·ç¦»
                        distance = abs(pos - len(processed_content) // 2)
                        if distance < min_distance:
                            min_distance = distance
                            best_split_pos = pos + len(pattern)
                        pos = processed_content.find(pattern, pos + 1)
            
            # å¦‚æœæ‰¾åˆ°äº†åˆé€‚çš„åˆ†å‰²ç‚¹ï¼Œè¿›è¡Œåˆ†å‰²
            if min_distance < float('inf') and best_split_pos > 10 and best_split_pos < len(processed_content) - 10:
                part1 = processed_content[:best_split_pos].strip()
                part2 = processed_content[best_split_pos:].strip()
                processed_content = f"{part1}[br]{part2}"
                console.print(f"[green]æ™ºèƒ½åˆ†å‰²æˆåŠŸ: åœ¨ä½ç½® {best_split_pos} å¤„åˆ†å‰²[/green]")
                has_valid_split = True
            else:
                # å¦‚æœæ— æ³•æ™ºèƒ½åˆ†å‰²ï¼Œåˆ™æŒ‰é•¿åº¦å¹³å‡åˆ†å‰²
                mid_point = len(processed_content) // 2
                # å¯»æ‰¾æœ€è¿‘çš„ç©ºæ ¼è¿›è¡Œåˆ†å‰²
                space_before = processed_content.rfind(' ', 0, mid_point)
                space_after = processed_content.find(' ', mid_point)
                
                if space_before != -1 and (space_after == -1 or mid_point - space_before <= space_after - mid_point):
                    split_pos = space_before + 1
                elif space_after != -1:
                    split_pos = space_after
                else:
                    split_pos = mid_point
                
                if split_pos > 5 and split_pos < len(processed_content) - 5:
                    part1 = processed_content[:split_pos].strip()
                    part2 = processed_content[split_pos:].strip()
                    processed_content = f"{part1}[br]{part2}"
                    console.print(f"[yellow]æŒ‰é•¿åº¦å¹³å‡åˆ†å‰²: åœ¨ä½ç½® {split_pos} å¤„åˆ†å‰²[/yellow]")
                    has_valid_split = True
                else:
                    console.print(f"[yellow]å†…å®¹å¤ªçŸ­ï¼Œæ— éœ€åˆ†å‰²ï¼Œä¿æŒåŸæ ·[/yellow]")
                    has_valid_split = True
            
            response_data[split_key] = processed_content
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿å¤„ç†åçš„å†…å®¹ä¸ä¸ºç©º
        final_content = response_data[split_key]
        if not final_content or final_content.strip() == "":
            console.print(f"[red]Error: å¤„ç†åçš„å†…å®¹ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹å¥å­[/red]")
            # ä½œä¸ºæœ€åçš„å®¹é”™æªæ–½ï¼Œä½¿ç”¨åŸå§‹å¥å­
            response_data[split_key] = original_sentence
            final_content = original_sentence
        
        # éªŒè¯åˆ†å‰²ç»“æœçš„åˆç†æ€§
        if '[br]' in final_content:
            parts = final_content.split('[br]')
            # æ£€æŸ¥åˆ†å‰²åçš„éƒ¨åˆ†æ˜¯å¦åˆç†
            valid_parts = [part.strip() for part in parts if part.strip()]
            if len(valid_parts) < 2:
                console.print(f"[yellow]Warning: åˆ†å‰²ååªæœ‰ {len(valid_parts)} ä¸ªæœ‰æ•ˆéƒ¨åˆ†ï¼Œå¯èƒ½åˆ†å‰²ä¸ç†æƒ³[/yellow]")
            elif any(len(part.strip()) < 3 for part in valid_parts):
                console.print(f"[yellow]Warning: æŸäº›åˆ†å‰²éƒ¨åˆ†è¿‡çŸ­ï¼Œå¯èƒ½å½±å“å­—å¹•è´¨é‡[/yellow]")
            else:
                console.print(f"[green]åˆ†å‰²éªŒè¯é€šè¿‡: å…± {len(valid_parts)} ä¸ªéƒ¨åˆ†[/green]")
        else:
            console.print(f"[yellow]Warning: æœ€ç»ˆå†…å®¹ä¸­æ²¡æœ‰[br]æ ‡è®°ï¼Œå°†ä½œä¸ºå•ä¸ªéƒ¨åˆ†å¤„ç†: {repr(final_content[:50])}...[/yellow]")
        
        console.print(f"[green]Success: éªŒè¯é€šè¿‡ï¼Œå†…å®¹å¤„ç†å®Œæˆ[/green]")
        return {"status": "success", "message": "Split completed"}
    
    response_data = ask_gpt(split_prompt + " " * retry_attempt, resp_type='json', valid_def=valid_split, log_title='split_by_meaning')
    
    # å®‰å…¨è·å–choiceå’Œå¯¹åº”çš„splitå†…å®¹
    choice = response_data.get("choice", "1")  # é»˜è®¤ä½¿ç”¨1
    
    # æŸ¥æ‰¾å®é™…å¯ç”¨çš„splitå­—æ®µ
    available_split_keys = [k for k in response_data.keys() if k.startswith('split') and k != 'split']
    
    if f"split{choice}" in response_data:
        best_split = response_data[f"split{choice}"]
    elif available_split_keys:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„splitå­—æ®µ
        best_split = response_data[available_split_keys[0]]
        console.print(f"[yellow]ä½¿ç”¨å¤‡ç”¨splitå­—æ®µ: {available_split_keys[0]}[/yellow]")
    else:
        console.print(f"[red]Error: æ— æ³•æ‰¾åˆ°ä»»ä½•splitå†…å®¹ï¼Œä½¿ç”¨åŸå§‹å¥å­[/red]")
        return sentence
    
    # æ£€æŸ¥best_splitæ˜¯å¦æœ‰æ•ˆ
    if not best_split or not isinstance(best_split, str):
        console.print(f"[red]Error: splitå†…å®¹æ— æ•ˆï¼Œä½¿ç”¨åŸå§‹å¥å­[/red]")
        return sentence
    
    split_points = find_split_positions(sentence, best_split)
    # split the sentence based on the split points
    for i, split_point in enumerate(split_points):
        if i == 0:
            best_split = sentence[:split_point] + '\n' + sentence[split_point:]
        else:
            parts = best_split.split('\n')
            last_part = parts[-1]
            parts[-1] = last_part[:split_point - split_points[i-1]] + '\n' + last_part[split_point - split_points[i-1]:]
            best_split = '\n'.join(parts)
    if index != -1:
        console.print(f'[green]âœ… Sentence {index} has been successfully split[/green]')
    table = Table(title="")
    table.add_column("Type", style="cyan")
    table.add_column("Sentence")
    table.add_row("Original", sentence, style="yellow")
    table.add_row("Split", best_split.replace('\n', ' ||'), style="yellow")
    console.print(table)
    
    return best_split

def parallel_split_sentences(sentences, max_length, max_workers, nlp, retry_attempt=0):
    """Split sentences in parallel using a thread pool."""
    new_sentences = [None] * len(sentences)
    futures = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        for index, sentence in enumerate(sentences):
            # Use tokenizer to split the sentence
            tokens = tokenize_sentence(sentence, nlp)
            # print("Tokenization result:", tokens)
            num_parts = math.ceil(len(tokens) / max_length)
            if len(tokens) > max_length:
                future = executor.submit(split_sentence, sentence, num_parts, max_length, index=index, retry_attempt=retry_attempt)
                futures.append((future, index, num_parts, sentence))
            else:
                new_sentences[index] = [sentence]

        for future, index, num_parts, sentence in futures:
            split_result = future.result()
            if split_result:
                split_lines = split_result.strip().split('\n')
                new_sentences[index] = [line.strip() for line in split_lines]
            else:
                new_sentences[index] = [sentence]

    return [sentence for sublist in new_sentences for sentence in sublist]

@check_file_exists(_3_2_SPLIT_BY_MEANING)
def split_sentences_by_meaning():
    """The main function to split sentences by meaning."""
    # read input sentences
    with open(_3_1_SPLIT_BY_NLP, 'r', encoding='utf-8') as f:
        sentences = [line.strip() for line in f.readlines()]

    nlp = init_nlp()
    # ğŸ”„ process sentences multiple times to ensure all are split
    for retry_attempt in range(3):
        sentences = parallel_split_sentences(sentences, max_length=load_key("max_split_length"), max_workers=load_key("max_workers"), nlp=nlp, retry_attempt=retry_attempt)

    # ğŸ’¾ save results
    with open(_3_2_SPLIT_BY_MEANING, 'w', encoding='utf-8') as f:
        f.write('\n'.join(sentences))
    console.print('[green]âœ… All sentences have been successfully split![/green]')

if __name__ == '__main__':
    # print(split_sentence('Which makes no sense to the... average guy who always pushes the character creation slider all the way to the right.', 2, 22))
    split_sentences_by_meaning()