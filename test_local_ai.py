#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VideoLingo æœ¬åœ°AIæœåŠ¡æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯Ollamaå’ŒWhisperæœ¬åœ°æœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import requests
import json
import os
import sys
from pathlib import Path

def test_ollama_connection():
    """æµ‹è¯•OllamaæœåŠ¡è¿æ¥"""
    print("ğŸ” æµ‹è¯•OllamaæœåŠ¡è¿æ¥...")
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"âœ… OllamaæœåŠ¡æ­£å¸¸è¿è¡Œ")
            print(f"ğŸ“¦ å·²å®‰è£…æ¨¡å‹æ•°é‡: {len(models)}")
            
            if models:
                print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
                for model in models:
                    print(f"   - {model.get('name', 'Unknown')}")
                return True, models
            else:
                print("âš ï¸  æ²¡æœ‰æ£€æµ‹åˆ°å·²å®‰è£…çš„æ¨¡å‹")
                print("ğŸ’¡ è¯·è¿è¡Œ: ollama pull qwen2")
                return True, []
        else:
            print(f"âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False, []
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
        print("ğŸ’¡ è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
        return False, []
    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        return False, []

def test_ollama_chat(model_name="qwen2"):
    """æµ‹è¯•Ollamaå¯¹è¯åŠŸèƒ½"""
    print(f"\nğŸ’¬ æµ‹è¯•Ollamaå¯¹è¯åŠŸèƒ½ (æ¨¡å‹: {model_name})...")
    try:
        payload = {
            "model": model_name,
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ"}
            ],
            "stream": False
        }
        
        response = requests.post(
            "http://localhost:11434/v1/chat/completions",
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            message = result.get('choices', [{}])[0].get('message', {}).get('content', '')
            print(f"âœ… å¯¹è¯æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ¤– æ¨¡å‹å›ç­”: {message[:100]}..." if len(message) > 100 else f"ğŸ¤– æ¨¡å‹å›ç­”: {message}")
            return True
        else:
            print(f"âŒ å¯¹è¯æµ‹è¯•å¤±è´¥: {response.status_code}")
            print(f"ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
            return False
    except Exception as e:
        print(f"âŒ å¯¹è¯æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False

def test_config_file():
    """æµ‹è¯•é…ç½®æ–‡ä»¶è®¾ç½®"""
    print("\nğŸ“‹ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    config_path = Path("config.yaml")
    
    if not config_path.exists():
        print("âŒ æ‰¾ä¸åˆ°config.yamlæ–‡ä»¶")
        return False
    
    try:
        import yaml
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        api_config = config.get('api', {})
        whisper_config = config.get('whisper', {})
        
        print("âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ")
        print(f"ğŸ”— APIåœ°å€: {api_config.get('base_url')}")
        print(f"ğŸ¤– APIæ¨¡å‹: {api_config.get('model')}")
        print(f"ğŸ¤ Whisperæ¨¡å¼: {whisper_config.get('runtime')}")
        print(f"âš™ï¸  æœ€å¤§å·¥ä½œçº¿ç¨‹: {config.get('max_workers')}")
        print(f"ğŸ“ æ‘˜è¦é•¿åº¦: {config.get('summary_length')}")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        checks = [
            (api_config.get('base_url') == 'http://localhost:11434/v1', "APIåœ°å€é…ç½®"),
            (api_config.get('model') == 'qwen2', "æ¨¡å‹é…ç½®"),
            (whisper_config.get('runtime') == 'local', "Whisperæœ¬åœ°æ¨¡å¼"),
            (config.get('max_workers') == 1, "å·¥ä½œçº¿ç¨‹æ•°é…ç½®"),
            (config.get('summary_length') == 2000, "æ‘˜è¦é•¿åº¦é…ç½®")
        ]
        
        all_good = True
        for check, desc in checks:
            if check:
                print(f"âœ… {desc}: æ­£ç¡®")
            else:
                print(f"âš ï¸  {desc}: å¯èƒ½éœ€è¦è°ƒæ•´")
                all_good = False
        
        return all_good
        
    except ImportError:
        print("âŒ ç¼ºå°‘PyYAMLåº“ï¼Œæ— æ³•è§£æé…ç½®æ–‡ä»¶")
        return False
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {str(e)}")
        return False

def test_whisper_local():
    """æµ‹è¯•Whisperæœ¬åœ°é…ç½®"""
    print("\nğŸ¤ æ£€æŸ¥Whisperæœ¬åœ°é…ç½®...")
    
    whisper_file = Path("core/asr_backend/whisperX_local.py")
    if whisper_file.exists():
        print("âœ… WhisperXæœ¬åœ°æ–‡ä»¶å­˜åœ¨")
        
        # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
        try:
            import whisperx
            print("âœ… WhisperXåº“å·²å®‰è£…")
        except ImportError:
            print("âŒ WhisperXåº“æœªå®‰è£…")
            return False
        
        try:
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"âœ… PyTorchå·²å®‰è£…ï¼Œè®¾å¤‡: {device}")
            if device == "cuda":
                gpu_count = torch.cuda.device_count()
                print(f"ğŸ® æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
        except ImportError:
            print("âŒ PyTorchåº“æœªå®‰è£…")
            return False
        
        return True
    else:
        print("âŒ WhisperXæœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ VideoLingo æœ¬åœ°AIæœåŠ¡æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•ç»“æœç»Ÿè®¡
    results = {
        'ollama_connection': False,
        'ollama_chat': False,
        'config_file': False,
        'whisper_local': False
    }
    
    # 1. æµ‹è¯•Ollamaè¿æ¥
    ollama_ok, models = test_ollama_connection()
    results['ollama_connection'] = ollama_ok
    
    # 2. å¦‚æœæœ‰æ¨¡å‹ï¼Œæµ‹è¯•å¯¹è¯åŠŸèƒ½
    if ollama_ok and models:
        model_name = models[0].get('name', 'qwen2')
        results['ollama_chat'] = test_ollama_chat(model_name)
    elif ollama_ok:
        print("\nâ³ æ¨¡å‹è¿˜åœ¨ä¸‹è½½ä¸­ï¼Œè·³è¿‡å¯¹è¯æµ‹è¯•")
    
    # 3. æµ‹è¯•é…ç½®æ–‡ä»¶
    results['config_file'] = test_config_file()
    
    # 4. æµ‹è¯•Whisperé…ç½®
    results['whisper_local'] = test_whisper_local()
    
    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    print(f"\nğŸ¯ æ€»ä½“çŠ¶æ€: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ­å–œï¼æœ¬åœ°AIæœåŠ¡é…ç½®å®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨VideoLingoäº†ï¼")
    elif passed >= total - 1:
        print("âš ï¸  åŸºæœ¬é…ç½®å®Œæˆï¼Œå¯èƒ½éœ€è¦ç­‰å¾…æ¨¡å‹ä¸‹è½½å®Œæˆ")
    else:
        print("âŒ é…ç½®å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°å¤±è´¥é¡¹ç›®")
    
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   - å¯åŠ¨æœåŠ¡: streamlit run st.py")
    print("   - è®¿é—®ç•Œé¢: http://localhost:8501")
    print("   - æŸ¥çœ‹æŒ‡å—: æœ¬åœ°AIéƒ¨ç½²æŒ‡å—.md")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)